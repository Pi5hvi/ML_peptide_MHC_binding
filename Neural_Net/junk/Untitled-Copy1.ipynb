{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Thing to grab all of our data from the ic50.csv file\n",
    "\n",
    "def datagrabber():\n",
    "    with open('ic50.csv', mode='r') as f:\n",
    "        r = csv.reader(f)\n",
    "        row_count = sum(1 for row in r)\n",
    "        row_count = row_count-1\n",
    "        \n",
    "    with open('ic50.csv', mode='r') as f:\n",
    "        r = csv.reader(f)\n",
    "        ic50_MHC = [\"\" for x in range(row_count)]\n",
    "        ic50_pept = [\"\" for x in range(row_count)]\n",
    "        ic50_HL = [\"\" for x in range(row_count)]\n",
    "        j=-2\n",
    "        for row in r:\n",
    "            i=0\n",
    "            j=j+1\n",
    "            for cell in row:\n",
    "                if i==11:#This is the peptide\n",
    "                    ic50_pept[j]=str(cell)\n",
    "                elif i==80:#This is the MHC\n",
    "                    try:\n",
    "                        allel_type=re.search('.*HLA-',str(cell))#Look for the key term\n",
    "                        MHC_name=str(cell).replace(allel_type[0], '')\n",
    "                        if MHC_name[0]=='A':\n",
    "                            with open('A_prot.fasta') as file:\n",
    "                                file_contents=file.read()\n",
    "                                allel=re.search(MHC_name,file_contents)\n",
    "                                print(allel.span,j)\n",
    "                                print('xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx')\n",
    "                    except:   \n",
    "                        print('exptn:'+str(cell))\n",
    "                elif i==72:#This is the HL\n",
    "                    i=i\n",
    "            \n",
    "            \n",
    "                i=i+1\n",
    "datagrabber()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## File conversion and getting the maximum length of an MHC\n",
    "\n",
    "\n",
    "\n",
    "def datacleaner():\n",
    "\n",
    "    #First find the number of rows in our input file\n",
    "    with open('test.csv', mode='r') as f:\n",
    "        r = csv.reader(f)\n",
    "        row_count = sum(1 for row in r)\n",
    "        row_count = row_count-1\n",
    "    \n",
    "    #Now, import all the data into arrays of strings called MHCstrs,peptstrs,HLstrs\n",
    "    with open('test.csv', mode='r') as f:\n",
    "        r = csv.reader(f)\n",
    "        maxMHC=0\n",
    "        maxpept=0\n",
    "        MHCstrs = [\"\" for x in range(row_count)]\n",
    "        peptstrs = [\"\" for x in range(row_count)]\n",
    "        HLstrs = [\"\" for x in range(row_count)]\n",
    "        j=-2\n",
    "        for row in r:\n",
    "            i=0\n",
    "            j=j+1\n",
    "            for cell in row:\n",
    "                if i==0: #This is the MHC\n",
    "                    m=re.search('.*SHS',str(cell))#This makes it so we look only after SHS\n",
    "                    try:\n",
    "                        MHC=str(cell).replace(m[0], '')\n",
    "                        MHCstrs[j]=MHC\n",
    "                        MHClength=(len(MHC))\n",
    "                        if maxMHC<MHClength:\n",
    "                            maxMHC=MHClength                    \n",
    "                    except:\n",
    "                        if str(cell)== 'MHC':#If we are in the titles row, this isn't an error\n",
    "                            i=i# As mentioned before, this isn't really an error\n",
    "                        else:\n",
    "                            print('NO SHS found for'+str(cell)) # Incase there is no SHS in our MHC\n",
    "                elif i==1: #This is the peptide\n",
    "                    peptstrs[j]=str(cell)\n",
    "                    if maxpept<len(str(cell)):\n",
    "                        maxpept=len(str(cell))\n",
    "                elif i==2:\n",
    "                    try:\n",
    "                        HLstrs[j]=int(str(cell),10)\n",
    "                    except:\n",
    "                        i=i #This will happen when we are in the titles row. Not a real error, so ignore\n",
    "                i=i+1\n",
    "                \n",
    "    #Now we can write all of our data to a new file, input.csv which has a seperate colom for each AA.\n",
    "    with open('input.csv', mode='w') as f:\n",
    "        w=csv.writer(f)\n",
    "        for i in range (row_count+1):\n",
    "            row=[]\n",
    "            if i==0:\n",
    "                for j in range (maxMHC):\n",
    "                    row.append('MHC'+str(j))\n",
    "                for j in range (maxpept):\n",
    "                    row.append('pept'+str(j))\n",
    "                row.append(\"HL\")\n",
    "            \n",
    "            else:\n",
    "                for j in range (maxMHC):\n",
    "                    try:\n",
    "                        row.append(MHCstrs[i-1][j])\n",
    "                    except:\n",
    "                        row.append(\"\")\n",
    "                for j in range (maxpept):\n",
    "                    try:\n",
    "                        row.append(peptstrs[i-1][j])\n",
    "                    except:\n",
    "                        row.append(\"\")\n",
    "                row.append(HLstrs[i-1])\n",
    "            w.writerow(row)\n",
    "\n",
    "\n",
    "    return maxMHC,maxpept\n",
    "\n",
    "#Importing the maxMHC and maxpept variables and taking input to pandas\n",
    "maxMHC,maxpept=datacleaner()\n",
    "ds=pd.read_csv(\"input.csv\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pandas converting all the MHC and peptide coloumns to 1HCs\n",
    "\n",
    "for i in range(maxMHC):\n",
    "\n",
    "    mhc=ds.pop('MHC'+str(i))\n",
    "    ds['MHC'+str(i)+'=A']=(mhc=='A')*1.0\n",
    "    ds['MHC'+str(i)+'=B']=(mhc=='B')*1.0\n",
    "    ds['MHC'+str(i)+'=C']=(mhc=='C')*1.0\n",
    "    ds['MHC'+str(i)+'=D']=(mhc=='D')*1.0\n",
    "    ds['MHC'+str(i)+'=E']=(mhc=='E')*1.0\n",
    "    ds['MHC'+str(i)+'=F']=(mhc=='F')*1.0\n",
    "    ds['MHC'+str(i)+'=G']=(mhc=='G')*1.0\n",
    "    ds['MHC'+str(i)+'=H']=(mhc=='H')*1.0\n",
    "    ds['MHC'+str(i)+'=I']=(mhc=='I')*1.0\n",
    "    ds['MHC'+str(i)+'=K']=(mhc=='K')*1.0\n",
    "    ds['MHC'+str(i)+'=L']=(mhc=='L')*1.0\n",
    "    ds['MHC'+str(i)+'=M']=(mhc=='M')*1.0\n",
    "    ds['MHC'+str(i)+'=N']=(mhc=='N')*1.0\n",
    "    ds['MHC'+str(i)+'=P']=(mhc=='P')*1.0\n",
    "    ds['MHC'+str(i)+'=Q']=(mhc=='Q')*1.0\n",
    "    ds['MHC'+str(i)+'=R']=(mhc=='R')*1.0\n",
    "    ds['MHC'+str(i)+'=S']=(mhc=='S')*1.0\n",
    "    ds['MHC'+str(i)+'=T']=(mhc=='T')*1.0\n",
    "    ds['MHC'+str(i)+'=U']=(mhc=='U')*1.0\n",
    "    ds['MHC'+str(i)+'=V']=(mhc=='V')*1.0\n",
    "    ds['MHC'+str(i)+'=W']=(mhc=='W')*1.0\n",
    "    ds['MHC'+str(i)+'=X']=(mhc=='X')*1.0\n",
    "    ds['MHC'+str(i)+'=Y']=(mhc=='Y')*1.0\n",
    "    ds['MHC'+str(i)+'=Z']=(mhc=='Z')*1.0\n",
    "    \n",
    "for i in range(maxpept):\n",
    "\n",
    "    mhc=ds.pop('pept'+str(i))\n",
    "    ds['pept'+str(i)+'=A']=(mhc=='A')*1.0\n",
    "    ds['pept'+str(i)+'=B']=(mhc=='B')*1.0\n",
    "    ds['pept'+str(i)+'=C']=(mhc=='C')*1.0\n",
    "    ds['pept'+str(i)+'=D']=(mhc=='D')*1.0\n",
    "    ds['pept'+str(i)+'=E']=(mhc=='E')*1.0\n",
    "    ds['pept'+str(i)+'=F']=(mhc=='F')*1.0\n",
    "    ds['pept'+str(i)+'=G']=(mhc=='G')*1.0\n",
    "    ds['pept'+str(i)+'=H']=(mhc=='H')*1.0\n",
    "    ds['pept'+str(i)+'=I']=(mhc=='I')*1.0\n",
    "    ds['pept'+str(i)+'=K']=(mhc=='K')*1.0\n",
    "    ds['pept'+str(i)+'=L']=(mhc=='L')*1.0\n",
    "    ds['pept'+str(i)+'=M']=(mhc=='M')*1.0\n",
    "    ds['pept'+str(i)+'=N']=(mhc=='N')*1.0\n",
    "    ds['pept'+str(i)+'=P']=(mhc=='P')*1.0\n",
    "    ds['pept'+str(i)+'=Q']=(mhc=='Q')*1.0\n",
    "    ds['pept'+str(i)+'=R']=(mhc=='R')*1.0\n",
    "    ds['pept'+str(i)+'=S']=(mhc=='S')*1.0\n",
    "    ds['pept'+str(i)+'=T']=(mhc=='T')*1.0\n",
    "    ds['pept'+str(i)+'=U']=(mhc=='U')*1.0\n",
    "    ds['pept'+str(i)+'=V']=(mhc=='V')*1.0\n",
    "    ds['pept'+str(i)+'=W']=(mhc=='W')*1.0\n",
    "    ds['pept'+str(i)+'=X']=(mhc=='X')*1.0\n",
    "    ds['pept'+str(i)+'=Y']=(mhc=='Y')*1.0\n",
    "    ds['pept'+str(i)+'=Z']=(mhc=='Z')*1.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Pranav/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/Pranav/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "train_ds=ds.sample(frac=0.8,random_state=0)\n",
    "test_ds=ds.drop(train_ds.index)\n",
    "train_labels=train_ds.pop('HL')\n",
    "test_labels=test_ds.pop('HL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Pranav/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12f6bfda0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model_hl=tf.keras.models.Sequential()\n",
    "#model_hl.add(tf.keras.layers.Dense(4, activation=tf.nn.relu, input_shape=[2]))\n",
    "#model_hl.add(tf.keras.layers.Dense(4, activation=tf.nn.relu))\n",
    "#model_hl.add(tf.keras.layers.Dense(1))\n",
    "model = keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(64, activation=tf.nn.relu, input_shape=[len(train_ds.keys())]))\n",
    "model.add(tf.keras.layers.Dense(64, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "    \n",
    "optimizer=tf.keras.optimizers.RMSprop(0.001)\n",
    "    \n",
    "model.compile(loss='mse',optimizer=optimizer,metrics=['mae','mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[488.28616]\n",
      " [302.86395]\n",
      " [247.87755]\n",
      " [668.9785 ]\n",
      " [368.07797]\n",
      " [302.86395]\n",
      " [562.28156]\n",
      " [331.19525]]\n"
     ]
    }
   ],
   "source": [
    "#class PrintDot(keras.callbacks.Callback):\n",
    "#    def on_epoch_end(self,epoch,logs):\n",
    "#        if epoch % 100 == 0: print('')\n",
    "#        print('.',end='')\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "model.fit(train_ds, train_labels, epochs=EPOCHS, validation_split=0.2,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([train_ds])\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
